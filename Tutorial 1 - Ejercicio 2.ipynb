{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=\"\"\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926419989107798016</th>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trabajar en #Ryanair como #TMA: https://t.co/r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri Nov 03 12:05:12 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934854385577943041</th>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Iberia @FIONAFERRER Cuando gusten en Cancún s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Nov 26 18:40:28 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945318406441635840</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sabiais que @Iberia te trata muy bien en santi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Dec 25 15:40:45 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927540721296568320</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NUNCA NUNCA NUNCA pidáis el café de Ryanair.\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Nov 06 14:18:35 +0000 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947965901332197376</th>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@cris_tortu @dakar @Iberia @Mitsubishi_ES @BFG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Jan 01 23:00:57 +0000 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buenos Aires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   airline_sentiment  is_reply  reply_count  retweet_count  \\\n",
       "tweet_id                                                                     \n",
       "926419989107798016           neutral     False            0              0   \n",
       "934854385577943041           neutral      True            0              0   \n",
       "945318406441635840          negative     False            0              0   \n",
       "927540721296568320          negative     False            0              0   \n",
       "947965901332197376          positive      True            0              0   \n",
       "\n",
       "                                                                 text  \\\n",
       "tweet_id                                                                \n",
       "926419989107798016  Trabajar en #Ryanair como #TMA: https://t.co/r...   \n",
       "934854385577943041  @Iberia @FIONAFERRER Cuando gusten en Cancún s...   \n",
       "945318406441635840  Sabiais que @Iberia te trata muy bien en santi...   \n",
       "927540721296568320  NUNCA NUNCA NUNCA pidáis el café de Ryanair.\\n...   \n",
       "947965901332197376  @cris_tortu @dakar @Iberia @Mitsubishi_ES @BFG...   \n",
       "\n",
       "                   tweet_coord                   tweet_created tweet_location  \\\n",
       "tweet_id                                                                        \n",
       "926419989107798016         NaN  Fri Nov 03 12:05:12 +0000 2017            NaN   \n",
       "934854385577943041         NaN  Sun Nov 26 18:40:28 +0000 2017            NaN   \n",
       "945318406441635840         NaN  Mon Dec 25 15:40:45 +0000 2017            NaN   \n",
       "927540721296568320         NaN  Mon Nov 06 14:18:35 +0000 2017            NaN   \n",
       "947965901332197376         NaN  Mon Jan 01 23:00:57 +0000 2018            NaN   \n",
       "\n",
       "                                 user_timezone  \n",
       "tweet_id                                        \n",
       "926419989107798016                      Madrid  \n",
       "934854385577943041                 Mexico City  \n",
       "945318406441635840                      Madrid  \n",
       "927540721296568320  Pacific Time (US & Canada)  \n",
       "947965901332197376                Buenos Aires  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_public.csv', encoding='utf-8', index_col='tweet_id')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"negative\": -1, \"neutral\": 0, \"positive\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'] # the features we want to analyze\n",
    "ylabels = df['airline_sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x000001B7F41BB4C0>)),\n",
       "                ('regression-ML', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "modelLR = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([('preprocessing', tfidf_vector),\n",
    "                 ('regression-ML', modelLR)])\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5945602440264361\n",
      "Logistic Regression Precision: [0.62679055 0.52453988 0.55495979]\n",
      "Logistic Regression Recall: [0.86208733 0.38658628 0.28395062]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "#print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",precision_score(y_test, predicted, average = None))\n",
    "print(\"Logistic Regression Recall:\",recall_score(y_test, predicted,average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "-1    3769\n",
       " 0    2609\n",
       " 1    1489\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['airline_sentiment'])[\"airline_sentiment\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, -1, ..., -1,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline([('preprocessing', tfidf_vector),\n",
    "                 ('clasificador', clf)])\n",
    "# model generation\n",
    "pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "predicted = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.48398576512455516\n",
      "Precision: [0.60683297 0.39852399 0.33333333]\n",
      "Recall: [0.59584665 0.40693293 0.33607682]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, predicted))\n",
    "print(\"Precision:\",precision_score(y_test, predicted, average = None))\n",
    "print(\"Recall:\",recall_score(y_test, predicted,average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=1)\n",
    "pipe = Pipeline([('preprocessing', tfidf_vector),\n",
    "                 ('clasificador', clf)])\n",
    "# model generation\n",
    "pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "predicted = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5704117946110828\n",
      "Precision: [0.60716953 0.50457666 0.46335079]\n",
      "Recall: [0.8658147  0.33232856 0.24279835]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, predicted))\n",
    "print(\"Precision:\",precision_score(y_test, predicted, average = None))\n",
    "print(\"Recall:\",recall_score(y_test, predicted,average = None))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
